---
title: "Round by Round Seed Distribution in NCAA Tournament"
author: "John Kane"
date: '2019-04-02'
slug: round-by-round-seed-distribution-in-ncaa-tournament
tags:
- basketball
- March Madness
- R
categories:
- basketball
- March Madness
- R
---

Most years filling out my bracket I work forwards through the games, meaning I start by picking first round games, then using an ever dwindling pool of teams, proceed all the way through selecting a Final Four and eventually a champion. That strategy has rarely paid off for me in bracket pools as I'm hardly competitive beyond the first two rounds.

The most points in bracket pools are scored in later rounds, so it doesn't make a lot of sense to limit your choices based on choices made in earlier rounds. So this year I wanted to try something different, informed by data. I wanted to fill out the bracket backwards, meaning select a champion first, then choose a championship matchup (that includes the champion), then choose a Final Four and so on to selecting the winners in the round of 32. I want to use data to inform each of those selections.


Last year I did an entire post on picking first round upsets[^7], analyzing how common each upset was and how many total we could expect. A natural extension to that analysis is to look at every round, not just the first. This analysis looks at every round of the tournament, but starting with the last round, the champion, rather than the first round. I want to determine, based on seeds, what the most likely outcomes for each round are. What seed combinations appear most frequently in the Sweet Sixteen or Elite Eight? Read on to find out and see how I got there using data.

## Data

The data comes from the Kaggle competition for March Madness[^1]. I didn't submit an entry to the contest but used the data for this analysis. There are several datasets included for those competing in the contest, but I'm interested in just two of them, one for tournament seeds and one for tournament results. 

```{r, echo = FALSE, include = FALSE}
data_path <- "/home/john/basketball/march_madness/2019/data/DataFiles/"
```


```{r, message=FALSE}
library(tidyverse)
library(knitr)
seeds <- read_csv(paste0(data_path,"NCAATourneySeeds.csv"))
results <- read_csv(paste0(data_path,"NCAATourneyCompactResults.csv"))
```

#### Determining which round each game was

The Kaggle data was missing one important piece of information - which round of the tournment each game was. To solve for this I had to rely on my knowledge of the NCAA tournament. I knew that at some point in the last 15 years or so the tournament added the play-in games on the Tuesday before the first round. Eventually addiontal play-in games were added first on the same Tuesday, then on the Wednesday before the first round. Additionally each round except for Final Four, Championship, and first years of the play-in games take place over two days. 

So the first four rounds occur on a total of 8 days, then the fifth and sixth rounds occur on one day each. So that makes 10 total days' worth of games preceding the play-in game era. When you include play-in games in the calculation you arrive at either 11 or 12 days' worth of games, depending on the year. 

The Kaggle data does provide the day of the season for each game, both regular season and tournament. To determine which day of the tournament each game was played on I first determined what the first day of the tournament was, then subtracted the day of each game from that value. 


```{r}
season_first_tourney_day <-
results %>%
  group_by(Season) %>%
  summarise(first_day = min(DayNum))

results_tourney_day <-
  results %>%
  inner_join(season_first_tourney_day, by = 'Season') %>%
  mutate(days_since_first = DayNum - first_day)
```

With Day 0 now coded as the first day of the tournament we can see how many different values there were for each game:
```{r}
table(results_tourney_day$days_since_first)
```

With that knowledge in hand I can count how many distinct days of games each tournament had. 

```{r}
results_tourney_day %>%
  group_by(Season) %>%
  summarise(count = n_distinct(days_since_first)) %>%
  ungroup() %>%
  group_by(count) %>%
  summarize(Seasons = paste(Season,collapse = ", ")) %>%
  kable()
```

The above tells me the play-in games were first played in 2001, and the second day of play-in games were added in 2011. Now I can manually code this information into the data. Play-in games are assigned to a round of "0."


```{r}
results_tourney_day <-
  results_tourney_day%>%
  mutate(round  = case_when(
    Season %in% c(1985:2000) & days_since_first %in% c(0,1)  ~ 1,
    Season %in% c(1985:2000) & days_since_first %in% c(2,3)  ~ 2,
    Season %in% c(1985:2000) & days_since_first %in% c(7,8)  ~ 3,
    Season %in% c(1985:2000) & days_since_first %in% c(9,10) ~ 4,
    Season %in% c(1985:2000) & days_since_first %in% c(16)   ~ 5,
    Season %in% c(1985:2000) & days_since_first %in% c(18)   ~ 6,
    Season %in% c(2001:2010) & days_since_first %in% c(0)    ~ 0,
    Season %in% c(2001:2010) & days_since_first %in% c(2,3)  ~ 1,
    Season %in% c(2001:2010) & days_since_first %in% c(4,5)  ~ 2,
    Season %in% c(2001:2010) & days_since_first %in% c(9,10) ~ 3,
    Season %in% c(2001:2010) & days_since_first %in% c(11,12)~ 4,
    Season %in% c(2001:2010) & days_since_first %in% c(18)   ~ 5,
    Season %in% c(2001:2010) & days_since_first %in% c(20)   ~ 6,
    Season %in% c(2011:2018) & days_since_first %in% c(0,1)  ~ 0,
    Season %in% c(2011:2018) & days_since_first %in% c(2,3)  ~ 1,
    Season %in% c(2011:2018) & days_since_first %in% c(4,5)  ~ 2,
    Season %in% c(2011:2018) & days_since_first %in% c(9,10) ~ 3,
    Season %in% c(2011:2018) & days_since_first %in% c(11,12)~ 4,
    Season %in% c(2011:2018) & days_since_first %in% c(18)   ~ 5,
    Season %in% c(2011:2018) & days_since_first %in% c(20)   ~ 6,
    TRUE ~ NA_real_))

```

Now that the round of each game has been coded I want to determine what the seed was for both the winning and losing team of each game. I can do this in two joins. The first joins the results data with the seed data but only where the winning team id matches the team ID in the seed data. The second join is similar, but done for the losing team.

```{r}
results_w_seeds <-
  results_tourney_day %>% select(Season,WTeamID,LTeamID,round) %>%
  inner_join(.,
             seeds %>% mutate(WSeed = str_sub(Seed,2,3)),
             by = c('Season','WTeamID' = 'TeamID')) %>%
  inner_join(.,
             seeds %>% mutate(LSeed = str_sub(Seed,2,3)),
             by = c('Season','LTeamID' = 'TeamID')) %>%
  select(Season,WSeed,LSeed,round)

head(results_w_seeds) %>% kable()
```

Now completed with data wrangling we can move onto the analysis!

## Seed Distributions by Round

To represent the different seed distributions I'll concatenate the count of each seed in that round together.

So if the Sweet Sixteen has:

* 3 1 seeds
* 4 2 seeds
* 3 3 seeds
* 2 4 seed
* 2 5 seeds
* 1 6 seeds
* 0 7 seeds
* 0 8 seeds
* 1 9 seeds
* 0 10, 11, 12, 13, 14, 15, 16 seeds

In the data I'll represent that as `3432210010000000`. 

#### R Functions: `coalesce_join()` and `round_summary()`

A challenge I encountered doing the following the analysis was that not every seed is represented as ever winning in every round. For example, a No. 5 seed has never won the championship, and a No. 16 seed has never appeared in the Sweet Sixteen, among others. As a result when I go to summarise the data those particular combinations don't appear in the data, and I'd like them to appear as `0`.

The approach I default to in these situations is to use what I call an anchor data frame that contains and then coalesce variables from the data summary dataset to the anchor data frame, so that if a value is absent from the summarized data (no No. 16 seeds in Sweet Sixteen) it will be populated by the value in the anchor dataframe. `dplyr` does have a `coalesce()` function, but you need to write out explicitly which variables you need to coalesce. 

While not prohibitive, it is tedius to do so for many variables. It would be nice if we could join two tables, and naturally coalesce the columns in both without explicitly coding each one. That's what the excellent `coalesce_join` function from Edward Visel's blog does[^5]. I'll be using it a lot in this analysis.

```{r}
coalesce_join <- function(x, y, 
                          by = NULL, suffix = c(".x", ".y"), 
                          join = dplyr::full_join, ...) {
    joined <- join(x, y, by = by, suffix = suffix, ...)
    # names of desired output
    cols <- union(names(x), names(y))
    
    to_coalesce <- names(joined)[!names(joined) %in% cols]
    suffix_used <- suffix[ifelse(endsWith(to_coalesce, suffix[1]), 1, 2)]
    # remove suffixes and deduplicate
    to_coalesce <- unique(substr(
        to_coalesce, 
        1, 
        nchar(to_coalesce) - nchar(suffix_used)
    ))
    
    coalesced <- purrr::map_dfc(to_coalesce, ~dplyr::coalesce(
        joined[[paste0(.x, suffix[1])]], 
        joined[[paste0(.x, suffix[2])]]
    ))
    names(coalesced) <- to_coalesce
    
    dplyr::bind_cols(joined, coalesced)[cols]
}
```

I make use of the `coalesce_join()` function each time I summarise a round of the tournament. Rather than repeat similar code (changing the round we're analzying, and what we want to call the variable) multiple times I've turned that piece of the analysis into a function. This function takes as input a round to analyze, `r`, and a variable name, `varname`, and returns a frequency table of seed distribution in that round. Passing things you want to be used as both a variable name and as a grouping variable later in the analysis chain is challenging. I'm making use of tools in the `rlang` package as well as helpful hints from Edwin Thoen's blog[^6].

```{r}
round_summary <- function(r,varname){
  
  varname_nm <- quo_name(varname)
  
  results_w_seeds %>%
  filter(round == r) %>%
  group_by(Season,WSeed) %>%
  summarise(count = n()) %>%
  spread(key = WSeed, value = count, fill = 0) %>%
  mutate(dummy = 1) %>%
  coalesce_join(.,
            tibble(`01` = 0,`02` = 0, `03` = 0, `04` = 0, `05` = 0, `06` = 0, `07` = 0, `08` = 0, `09` = 0, `10` = 0, 
                   `11` = 0, `12` =0, `13` = 0, `14` = 0, `15` = 0, `16` = 0, dummy = 1),
            by = "dummy") %>%
  mutate(!!varname_nm := paste0(`01`,`02`,`03`,`04`,`05`,`06`,`07`,`08`,`09`,`10`,`11`,`12`,`13`,`14`,`15`,`16`)) %>%
  group_by(!!varname) %>%
  summarise(count = n()) %>%
  mutate(pct = paste(round(100*count/sum(count),1),"%")) %>%
  arrange(desc(count)) %>%
  kable()
}
```


Now, finally, onto the analysis. 

#### Champion

```{r}
round_summary(6, quo(champion))
```

This result was surprising to me. I expected No. 1 seeds to win more than any other seeds, maybe around 50% of the time but not over 60% of the time. A good strategry for filling out a winning bracket would definitely seem to mean picking one of the four No. 1 seds to win unless you had a very good reason for selecting a No. 2 or No. 3 seed. 

#### Championship Game

```{r}
round_summary(5,quo(championshipgame))
```

Given that No. 1 seeds win the tournament over 60% of the time we'd expect them to appear in most championship games. That is indeed the case with at least 1 No. 1 seed appearing in 7 of the 8 most frequently occurring champsionship matchups. Selecting a No. 1 and a No. 2 seed or two No. 1 seeds has occurred just under 50% of the time.

#### Final Four

```{r}
round_summary(4,quo(finalfour))
```

This was another surprising result to me. There are 34 years worth of data and 25 distinct seed combinations in the Final Four. No single seed combinations happens even 10% of the time so it is hard to make any kind of recommendation, apart from choosing a combination of Nos. 1, 2, and 3 seeds. 

Given that the Final Four doesn't isn't amenable to a tidy analysis like I had hoped, I have very little hope for earlier rounds. To test this I'll look at how many distinct distributions of seeds there has been in each round. 

## Distinct Seed Distributions by Round

If the Final Four has 25 distinct seed combinations in 34 years, what about the other rounds? Here I'll count 

```{r}
results_w_seeds %>%
  filter(round > 0) %>%
  group_by(Season,round,WSeed) %>%
  summarise(count = n()) %>%
  spread(key = WSeed, value = count, fill = 0) %>%
  mutate(seed_dist = paste0(`01`,`02`,`03`,`04`,`05`,`06`,`07`,`08`,`09`,`10`,`11`,`12`,`13`,`14`,`15`,`16`)) %>%
  select(Season,round,seed_dist) %>%
  ungroup() %>%
  group_by(round) %>%
  summarise(years = n(),
            distinct_dist = n_distinct(seed_dist))
```

I knew that there are seemingly infinite[^2] number of possible brackets, but I also thought that by collapsing the data into respective seeds that it would reduce some of that complexity. After summarzing the data in the table above, from 1985-2018 there has never been a repeat seed distribution in either the first or second round of the tournament! The Sweet Sixteen and Elite Eight also have had only 9 and 3, respectively, non-duplicate values.

The data has laid waste to by intended analysis and bracket strategy. Rather than looking at the actual seed distributions for each round I'll need to summarize those distributions. 

## Average Seed Distribution by Round

Since it isn't helpful to look at the actual distributions and their frequencies by round, we can summarize those distributions by taking the average. 


CLEAN UP THIS ANALYSIS

```{r, warning = FALSE}
results_w_seeds %>%
  filter(round > 0) %>%
  group_by(Season,round,WSeed) %>%
  summarise(count = n()) %>%
  spread(key = WSeed, value = count, fill = 0) %>%
  ungroup() %>%
  select(-Season) %>%
  group_by(round) %>%
  summarise_if(is_numeric,mean,na.rm = TRUE) %>%
  mutate_if(is_numeric,round,1) %>%
  kable()
```

#### Creating recomendations from these averages


## 2019 Results

How did the 2019 tournament play out with respect to these averages? Read on below...

#### Round of 32

| Seed   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| Average|4.0|3.8|3.4|3.2|2.6|2.5|2.5|2.0|2.0|1.5 |1.5 | 1.4|0.8 |0.6 |0.2 | 0.0|
| 2019   | 4 | 4 | 4 | 3 | 1 | 3 | 1 | 0 | 4 | 3  |  1 |  3 |  1 |  0 |  0 | 0  |

#### Sweet 16

| Seed   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| Average|3.4|2.5|2.1|1.9|1.4|1.2|0.8|0.4|0.2|0.7 |0.6 | 0.6|0.2 | 0.1| 0.0|0.0 |
| 2019   | 4 | 4 | 4 | 2 | 1 | 0 | 0 | 0 | 0 | 0  | 0  | 0  |  0 |  0 |  0 |  0 |

#### Elite 8

| Seed   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| Average|2.8|1.8|1.0|0.6|0.2|0.4|0.3|0.2|0.1|0.2 |0.2 | 0.6|0.0 | 0.0| 0.0|0.0 |
| 2019   | 3 | 2 | 2 | 0 | 1 | 0 | 0 | 0 | 0 | 0  |  0 |  0 |  0 |  0 |  0 |  0 |

#### Final Four

| Seed   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| Average|1.6|0.8|0.5|0.4|0.2|0.1|0.1|0.1|0.0|0.0 |0.1 |0.0 |0.0 |0.0 |0.0 |0.0 |
| 2019   | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0  |  0 |  0 |  0 |  0 |  0 |  0 |

#### Championship Game

| Seed   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| Average|1.0|0.4|0.3|0.1|0.1|0.1|0.0|0.1|0.0|0.0 |0.0 |0.0 | 0.0|0.0 |0.0 |0.0 |
| 2019   | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0  |  0 |  0 |  0 |  0 |  0 |  0 |

#### Champion

| Seed   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |
|--------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|
| Average|0.6|0.1|0.1|0.0|0.0|0.0|0.0|0.0|0.0|0.0 |0.0 |0.0 |0.0 |0.0 |0.0 |0.0 | 
| 2019   | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  |  0 |  0 |  0 |  0 |  0 |  0 | 

## Closing Thoughts

The first two rounds of the tournament were chalky[^3], which lends itself nicely to using long run averages, as over that timeframe the higher seeds are generally better teams and happen to win. 

The more difficult piece to this is the logical extension of knowing how many of each seed are likely to advance to the next
round. For example, I know there are on average going to be 2 No. 1 seeds in the Final Four, which 2 No. 1 seeds do I pick?

My approach this year was to use the pre tournament probabilities from 538[^4]. So I selected the No. 1 seed with the highest pre-tournament probability of winning the championship (Duke, ~28%)


Next year: expand to looking at conditional distributions. So Conditional on a No. 1 seed winning the tournament, what is the average distribution. Then conditional on the chosen championship game, what is the average final four. And so on...


[^1]:https://www.kaggle.com/c/mens-machine-learning-competition-2019
[^2]:https://www.ncaa.com/news/basketball-men/bracketiq/2019-03-20/perfect-ncaa-bracket-absurd-odds-march-madness-dream
[^3]:https://projects.fivethirtyeight.com/2019-march-madness-predictions/
[^4]:https://www.cbssports.com/college-basketball/news/march-madness-2019-chalk-has-ruled-the-ncaa-tournament-so-far-but-that-sets-up-what-could-be-a-great-sweet-16/
[^5]:https://alistaire.rbind.io/blog/coalescing-joins/
[^6]:https://edwinth.github.io/blog/dplyr-recipes/
[^7}:https://www.johnckane.com/blog/ncaa-first-round-upsets/